<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>TICR pipeline · PhyloNetworks.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../../"><img class="logo" src="../../assets/logo.png" alt="PhyloNetworks.jl logo"/></a><h1>PhyloNetworks.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../installation/">Installation</a></li><li><a class="toctext" href="../inputdata/">Input Data for SNaQ</a></li><li class="current"><a class="toctext" href>TICR pipeline</a><ul class="internal"><li><a class="toctext" href="#To-run-MrBayes:-we-already-have-alignments-1">To run MrBayes: we already have alignments</a></li><li><a class="toctext" href="#To-run-mbsum-on-the-output-of-MrBayes-for-each-gene-1">To run mbsum on the output of MrBayes for each gene</a></li><li><a class="toctext" href="#To-run-bucky-on-all-4-taxon-sets:-we-already-have-the-mbsum-output-1">To run bucky on all 4-taxon sets: we already have the mbsum output</a></li></ul></li><li><a class="toctext" href="../snaq_plot/">Network estimation and display</a></li><li><a class="toctext" href="../dist_reroot/">Network comparison and manipulation</a></li><li><a class="toctext" href="../fixednetworkoptim/">Candidate Networks</a></li><li><a class="toctext" href="../expectedCFs/">Extract Expected CFs</a></li><li><a class="toctext" href="../bootstrap/">Bootstrap</a></li><li><a class="toctext" href="../multiplealleles/">Multiple Alleles</a></li><li><a class="toctext" href="../trait_tree/">Continuous Trait Evolution</a></li><li><a class="toctext" href="../parsimony/">Parsimony on networks</a></li><li><a class="toctext" href="../fitDiscrete/">Discrete Trait Evolution</a></li><li><a class="toctext" href="../nj/">Neighbour Joining</a></li></ul></li><li><span class="toctext">Library</span><ul><li><a class="toctext" href="../../lib/public/">Public</a></li><li><a class="toctext" href="../../lib/internals/">Internals</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Manual</li><li><a href>TICR pipeline</a></li></ul><a class="edit-page" href="https://github.com/crsl4/PhyloNetworks.jl/blob/master/docs/src/man/ticr_howtogetQuartetCFs.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>TICR pipeline</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="TICR-pipeline-1" href="#TICR-pipeline-1">TICR pipeline</a></h1><p>PhyloNetworks&#39; <a href="https://github.com/crsl4/PhyloNetworks.jl/wiki/TICR:-from-alignments-to-quartet-concordance-factors">wiki</a> has a step-by-step tutorial, to go from multiple sequence alignments to a table of quartet gene frequencies (concordance factors: CFs), through BUCKy (to integrate out gene tree uncertainty) or through RAxML. To get the <code>raxml.pl</code> perl script to run RAxML on each gene, download the content of that wiki with</p><p><code>git clone https://github.com/crsl4/PhyloNetworks.jl.wiki.git</code></p><p>then go to the <code>script/</code> folder.   Full information and code is <a href="https://github.com/nstenz/TICR">here</a>. Below is more detail to insert data into the pipeline at various stages, using one of <strong>two pipelines</strong>, depending on your machine configuration:</p><ul><li><p>&quot;no-scheduler&quot; pipeline: original set of Perl scripts from the TICR pipeline, well suited for a machine or a cluster of machines without a job scheduler. The scripts automatically parallelize the work across the available cores.</p></li><li><p>&quot;slurm&quot; pipeline: well suited for a cluster where users submit jobs via a job scheduler like <a href="https://slurm.schedmd.com/">SLURM</a> or <a href="https://en.wikipedia.org/wiki/Oracle_Grid_Engine">SGE</a>. The job scheduler does the work of parallelizing the work across available cores. The scripts, in this second pipeline, were created to take full advantage of job scheduler capabilities. They were developed for a cluster running SLURM. Adjustments to the submit scripts will be needed, to adapt to your own SLURM configuration or to the syntax that your job scheduler wants.</p></li></ul><h2><a class="nav-anchor" id="To-run-MrBayes:-we-already-have-alignments-1" href="#To-run-MrBayes:-we-already-have-alignments-1">To run MrBayes: we already have alignments</a></h2><h3><a class="nav-anchor" id="no-scheduler-pipeline-1" href="#no-scheduler-pipeline-1">no-scheduler pipeline</a></h3><p>We don&#39;t need to run <code>mdl.pl</code> if we already have aligned gene sequences from separate loci. To run MrBayes on each locus, we can simply create a tarball of the Nexus files we wish to use (fasta won&#39;t work at this stage). The command below assumes that we want to use all the files ending with &quot;.nex&quot; in the current directory, one file per locus:</p><pre><code class="language-bash">tar czf my-genes.tar.gz *.nex</code></pre><p>Once the tarball has been successfully generated, we can then specify this file as input for <a href="https://github.com/nstenz/TICR/blob/master/scripts/mb.pl">mb.pl</a> assuming we have a valid MrBayes block located in the file &quot;bayes.txt&quot;:</p><pre><code class="language-bash">mb.pl my-genes.tar.gz -m bayes.txt -o my-genes-mb</code></pre><p>If we get an error message like <code>mb.pl: Command not found</code>, it might be because <code>mb.pl</code> has no execute permission, or the current directory is not in our &quot;path&quot;. An easy fix is to run this command instead:</p><pre><code class="language-bash">perl mb.pl my-genes.tar.gz -m bayes.txt -o my-genes-mb</code></pre><p>The resulting output tarball would now be located in <code>my-genes-mb/my-genes.mb.tar</code>, and can be used normally with <a href="https://github.com/nstenz/TICR/blob/master/scripts/bucky.pl">bucky.pl</a>, that is, like this:</p><pre><code class="language-bash">bucky.pl my-genes-mb/my-genes.mb.tar -o mygenes-bucky</code></pre><p>The output, with the table of concordance factors for all sets of 4 taxa, will be in a file named <code>my-genes.CFs.csv</code> inside a directory named <code>mygenes-bucky</code>. That&#39;s the file containing the quartet concordance factors to give to SNaQ as input. There is <em>no</em> need to do any of the steps below: they are already done by <code>bucky.pl</code>.</p><h3><a class="nav-anchor" id="slurm-pipeline-1" href="#slurm-pipeline-1">slurm pipeline</a></h3><p>SLURM will parallelize the MrBayes runs across genes.</p><ol><li><p>Navigate in some &quot;working&quot; directory where you place:</p><ul><li>a folder containing all nexus files, which we will call &quot;nexusfolder&quot; below</li><li>a text file named <code>mb-block.txt</code> with the MrBayes block to be used</li></ul><p>for all the genes (containing the options for MrBayes: model of sequence evolution, number of generations etc.). If we want a different MrBayes block for different genes, step 2 should be skipped, and we should instead find some other way to put the specific MrBayes block at the end of each nexus file.</p></li><li><p>In the &quot;working&quot; directory above, run the julia script <a href="https://github.com/nstenz/TICR/blob/master/scripts-cluster/paste-mb-block.jl"><code>paste-mb-block.jl</code></a> with &quot;nexusfolder&quot; as argument, to tell the script where to find all the nexus files:</p><pre><code class="language-bash">julia path/to/paste-mb-block.jl nexusfolder</code></pre><p>This script will read all the nexus files in the directory <code>nexusfolder</code>, will create a new directory <code>nexusfolder-block</code>, and will create new nexus files (containing the MrBayes block found in file <code>mb-block.txt</code>) as <code>1.nex, 2.nex, ...</code> in the new directory. A <code>translate.txt</code> file will also be created to map the original gene file names to the new (numbered) file names. If we named our MrBayes block file differently: we can edit the script and modify it to replace <code>mb-block.txt</code> by our actual file name for the MrBayes block.</p></li><li><p>Modify the submit script <a href="https://github.com/nstenz/TICR/blob/master/scripts-cluster/mb-slurm-submit.sh"><code>mb-slurm-submit.sh</code></a>, which will parallelize all the individual-gene MrBayes runs with SLURM:</p><ul><li>change <code>--array</code> to the correct number of genes</li><li>change <code>--mail-user</code> to the user&#39;s email (if this is an option for your job scheduler)</li><li>replace the <code>/workspace/software/bin</code> in <code>PATH=&quot;/workspace/software/bin:$PATH&quot;</code> to the path where the <code>mb</code> executable is located or put the whole path in the command: <code>/s/mrbayes-3.2.6-1/bin/mb</code></li></ul><p>In slurm, we can then submit the MrBayes array job with:</p><pre><code class="language-bash">sbatch mb-slurm-submit.sh</code></pre></li></ol><p>With this slurm pipeline, the steps below are needed: keep reading.</p><h2><a class="nav-anchor" id="To-run-mbsum-on-the-output-of-MrBayes-for-each-gene-1" href="#To-run-mbsum-on-the-output-of-MrBayes-for-each-gene-1">To run mbsum on the output of MrBayes for each gene</a></h2><p>If we have the output of MrBayes and want to run BUCKy, we must first run <code>mbsum</code> on the output from MrBayes, separately for each gene.</p><p>For a gene with output tree files named <code>gene1.run1.t</code>, <code>gene1.run2.t</code> and <code>gene1.run3.t</code>, and a desired burnin of 1000 trees per tree file, we do this:</p><pre><code class="language-bash">mbsum -n 1000 -o gene1.in gene1.run1.t gene1.run2.t gene1.run3.t</code></pre><p>This <code>mbsum</code> command will need to be executed for each gene. Then we can continue to the next section to run bucky.</p><p>Alternatively, we can use the julia script <a href="https://github.com/nstenz/TICR/blob/master/scripts-cluster/mbsum-t-files.jl"><code>mbsum-t-files.jl</code></a>, and give it as argument the directory that has the output tree files from MrBayes, to run mbsum for <em>all</em> the genes. <code>mbsum</code> is fast, so there is no attempt to parallelize the various mbsum commands.</p><pre><code class="language-bash">julia mbsum-t-files.jl mbfolder outputfolder burnin                # or
julia --color=yes -- mbsum-t-files.jl mbfolder outputfolder burnin # for colorized messages to the screen</code></pre><p>where <code>burnin</code> is replaced by the number of trees to ignore in each tree file for burnin. This <code>burnin</code> argument is optional (default: 2501). The <code>outputfolder</code> will contain the output of <code>mbsum</code>.</p><h2><a class="nav-anchor" id="To-run-bucky-on-all-4-taxon-sets:-we-already-have-the-mbsum-output-1" href="#To-run-bucky-on-all-4-taxon-sets:-we-already-have-the-mbsum-output-1">To run bucky on all 4-taxon sets: we already have the mbsum output</a></h2><h3><a class="nav-anchor" id="no-scheduler-pipeline-2" href="#no-scheduler-pipeline-2">no-scheduler pipeline</a></h3><p>If we already ran <code>mbsum</code> on the output from MrBayes, for each individual gene, we can simply create a tarball containing all the mbsum output files. So if we had mbsum output in files named <code>gene1.in</code>, <code>gene2.in</code>, ... , <code>gene100.in</code>, we would want to run something similar to the following command to create the tarball:</p><pre><code class="language-bash">tar czf my-genes-mbsum.tar.gz gene*.in</code></pre><p>We can now use this tarball along with the <code>-s</code> option in <a href="https://github.com/nstenz/TICR/blob/master/scripts/bucky.pl">bucky.pl</a> like this:</p><pre><code class="language-bash">bucky.pl my-genes-mbsum.tar.gz -s -o mygenes-bucky</code></pre><p>Again, if we get an error like <code>bucky.pl: Command not found</code>, we could run instead</p><pre><code class="language-bash">perl bucky.pl my-genes-mbsum.tar.gz -s -o mygenes-bucky</code></pre><p>The output, with the table of concordance factors for all sets of 4 taxa, will be in a file named <code>my-genes.CFs.csv</code> inside directory <code>mygenes-bucky</code>. That&#39;s the file containing the quartet concordance factors to give to SNaQ as input.</p><h3><a class="nav-anchor" id="slurm-pipeline-2" href="#slurm-pipeline-2">slurm pipeline</a></h3><p>We want to run <code>bucky</code> on every 4-taxon set. SLURM will parallelize these jobs with the submit script <a href="https://github.com/nstenz/TICR/blob/master/scripts-cluster/bucky-slurm-submit.sh"><code>bucky-slurm-submit.sh</code></a>, which calls the perl script <a href="https://github.com/nstenz/TICR/blob/master/scripts-cluster/bucky-slurm.pl"><code>bucky-slurm.pl</code></a>.</p><p>The perl script <a href="https://github.com/nstenz/TICR/blob/master/scripts-cluster/bucky-slurm.pl"><code>bucky-slurm.pl</code></a> runs <code>bucky</code> on a single 4-taxon set. It takes the following arguments, which must be modified in the submit script <a href="https://github.com/nstenz/TICR/blob/master/scripts-cluster/bucky-slurm-submit.sh"><code>bucky-slurm-submit.sh</code></a>:</p><ul><li>name of the folder containing the <code>mbsum</code> output files (one per locus) from previous step. This folder is named <code>mbsum</code> in the submit script: adapt if needed.</li><li>output name: <code>-o</code> or <code>--out-dir</code> name of the directory to store output files in. This option is not used in the default submit script</li><li>bucky arguments: <code>-a</code> or <code>--alpha</code> for the prior alpha value, and <code>-n</code> or <code>--ngen</code> number of generations. These options are not used either, in the script: the defaults are used then (α=1, 1 million generations)</li><li>integer for the given quartet, via option <code>-q</code>. The quartet ID is specified by SLURM with its own array ID: <code>$SLURM_ARRAY_TASK_ID</code>.</li></ul><p>In the submit script that gives instructions to the job scheduler:</p><ul><li>adapt the name of the <code>$SLURM_ARRAY_TASK_ID</code> variable, which captures the task number in the array of tasks, to your scheduler syntax</li><li>change <code>--array</code> to the correct number of 4-taxon sets. For example, if there are 15 taxa in the dataset, there are <code>1365</code> 4-taxon sets. To get this number, if you are unsure, use <code>choose(15,4)</code> in R or <code>binomial(15,4)</code> in Julia, but replace 15 by your actual number of individuals.</li><li>change <code>--mail-user</code> to the user&#39;s email (if this is an option for your job scheduler)</li><li>replace the <code>/workspace/software/bin</code> in <code>PATH=&quot;/workspace/software/bin:$PATH&quot;</code> by the path where the <code>bucky</code> executable is located. Also, replace <code>/workspace/claudia/software/TICR/scripts/</code> by the full path where the <code>bucky-slurm.pl</code> script is located.</li></ul><p>In slurm, we would submit the BUCKy array job with:</p><pre><code class="language-bash">sbatch bucky-slurm-submit.sh</code></pre><p>At the end, the array job will produce</p><ul><li>a <code>.concordance</code> file for every 4-taxon set</li><li>a <code>.cf</code> file with the parsed output for that same 4-taxon set, in the format needed for the final CF table.</li></ul><p>The <code>.cf</code> files can be concatenated to produce the file containing the quartet concordance factors across all 4-taxon sets, to give to SNaQ as input:</p><pre><code class="language-bash">cat *.cf &gt; CFtable.csv</code></pre><p>Alternatively, if the list of <code>.cf</code> files is not easily captured by <code>*.cf</code> (because the list is too long for a shell command), the following julia script can do the concatenation. Just copy-paste the commands below within a Julia session, started from the directory that contains the <code>.cf</code> files:</p><pre><code class="language-julia">files = String[] # empty vector of strings: will contain the .cf file names later
for f in filter(x -&gt; endswith(x, &quot;.cf&quot;), readdir())
    push!(files,f)
end
println(&quot;found $(length(files)) cf files&quot;) # to check how many .cf output files were found
open(&quot;CFtable.csv&quot;,&quot;w&quot;) do f_out
  # write the header:
  write(f_out, &quot;taxon1,taxon2,taxon3,taxon4,CF12_34,CF12_34_lo,CF12_34_hi,CF13_24,CF13_24_lo,CF13_24_hi,CF14_23,CF14_23_lo,CF14_23_hi,ngenes\n&quot;)
  for file in files
    @show file # to see the .cf file name: comment this out if that&#39;s too much screen output
    open(file) do f_in
        line = read(f_in, String)
        write(f_out, string(line,&quot;\n&quot;))
    end # closes &quot;file&quot; safely
  end
end # closes &quot;CFtable.csv&quot; safely</code></pre><p>When this is done, we will have a file <code>CFtable.csv</code> containing the quartet concordance factors, to give to SNaQ as input :smiley:</p><footer><hr/><a class="previous" href="../inputdata/"><span class="direction">Previous</span><span class="title">Input Data for SNaQ</span></a><a class="next" href="../snaq_plot/"><span class="direction">Next</span><span class="title">Network estimation and display</span></a></footer></article></body></html>
